{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "PyLIE: Testing Framework<br>\n",
    "=======================\n",
    "17 October 2017\n",
    "==============\n",
    "<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are 4 main reasons to develop a comprehensive test suite:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) Testing makes sure your code works properly under a given set of conditions (e.g. git clone, pip install, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2) Testing allows one to ensure that changes to the code did not break existing functionality (hotfixes and feature additions can and will break existing code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3) Testing forces one to think about the code under unusual conditions, possibly revealing logical errors (think of edge cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4) Good testing requires modular, decoupled code, which is a hallmark of good system design (if everything is decoupled, then it is also reusable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Exception Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The first step many coders take to handle weird use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideOutput": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "try:\n",
    "    for i in range(10):\n",
    "        print(2%i)\n",
    "except ZeroDivisionError\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* There are many built-in [exceptions](https://www.programiz.com/python-programming/exceptions) already. However, a user can always define their own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Custom Exceptions:\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class CustomException(Exception):\n",
    "    \"\"\"Raise some special exception because of a use case that inherits from the Exception Class\"\"\"\n",
    "    def __init__(self):\n",
    "        Exception.__init__(self, 'Zero Dummy')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* This can obviously be more complex than this, like passing in context dictionaries, but we are keeping this simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Now, if instead of division by zero, we can raise our custom exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "CustomException",
     "evalue": "Zero Dummy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-242d1155b7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mCustomException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCustomException\u001b[0m: Zero Dummy"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        raise CustomException\n",
    "    print(i%2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Doctest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The simplest form of testing framework invoked by `python -m doctest -v <file>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Uses `__doc__` (docstrings) to perform test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "def foo():\n",
    "    \"\"\"example function\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    >>>foo() is None\n",
    "    True\n",
    "    \"\"\"\n",
    "    return None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The doctest module searches for pieces of text that look like interactive Python sessions, and then executes those sessions to verify that they work exactly as shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is where we come to writing a failing test. Why would we do that?\n",
    "========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A extreme version of this is called **T**est **D**riven **D**evelopment (TDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* TDD means to write the tests first, *then* write the functions to match them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* This means your code is inherintly decoupled **AND** you wrote your functions knowing the edge cases beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A Python built-in test development suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Every test is wrapped in a class that inherits from unittest.TestCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Each test is meant to test a single **unit** of code in *isolation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* That means that the test should be able to pull out the specific parts of your module and test it without any other functions imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Test names should be meaningful, so that when they fail--and they *should*--you can tell what test it was and why it failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Every test declaration requires the `test_` prefix for unittest's test detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example `test.py` file:\n",
    "```python\n",
    "import unittest\n",
    "import sys\n",
    "sys.path.append('/path/to/application/app/folder')\n",
    "from app import function\n",
    "\n",
    "class CustomTestCase(unittest.TestCase):\n",
    "    \"\"\"Tests for `function.py`. This is the test class that defines the test cases\"\"\"\n",
    "\n",
    "    def test_if_function_works(self):\n",
    "        \"\"\"Is five successfully determined to be prime?\"\"\"\n",
    "        self.assertTrue(function())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main() # This piece allows us to invoke the test suite via the command line\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* A group of tests that interrogate similiar subsets of the module can be grouped into a `unittest.TestSuite()` for additional organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* It is normal to have both basic and advanced test suites available. Basic test suites for just making sure the module works as intended. Advanced can envelope benchmarking & optimization, extreme edge cases, and OS-specific testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assertion:\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [Assertions](https://docs.python.org/3.6/library/unittest.html#assert-methods) are the key components of a testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Assertions test if the outcome is expected. Some examples are `assertNotEqual()`, `assertIs()`, and `assertIn()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Moreover, one can test to see if their function performs exception handling or logging correctly with `assertRaises()` and `assertLogs()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Additionally:\n",
    "========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* you can use `setUp()` and `tearDown()` methods to add complexity to your testing environment.<br>\n",
    "*an example of this is to perturb a variable in such a way that your module could never produce just to see how your module will handle it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ***Furthermore***, you can add decorators onto your tests to either skip them (`@unittest.skip('message')`) or mark the expectation of a failure (`@unittest.expectedFailure`). The latter case is important because you may want your test to fail on some edge case, and therefore (for reporting reasons) if it does, then it passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. PyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* I generally don't like dealing with classes. Class inheritance, instantiation, and the whole `self` thing bothers me. Furthermore, I just don't like Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Secondly, while `assert` is great, it is also complex...and many tests have to be contrived to boil down results into the basic categories facilitated by `assert`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Thirdly, unless care was used for proper logging with unittest, anytime a test was used over a range that led to failure, the index at that given test case was lost. PyTest automatically reports these indicies in its reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* PyTest correct these issues...and it is native in all Anaconda builds of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Still need a `*_test.py` file and tests still need be called `test_*` though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# foo.py\n",
    "\n",
    "def Foo(number: int) -> str:\n",
    "    \"\"\"Our practice function\n",
    "    \n",
    "    Args:\n",
    "        number (int): some number\n",
    "    \n",
    "    Returns:\n",
    "        output (str): string representation of the integer\n",
    "\n",
    "    Raises:\n",
    "        TypeError: Please provide a integer argument.\n",
    "        \n",
    "    \"\"\"\n",
    "    if type(number) != int:\n",
    "        raise TypeError('Please provide a string argument')\n",
    "    else:\n",
    "        output = f'{number}'\n",
    "        print(f'The number entered was {output}')\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# test_foo.py\n",
    "\n",
    "import pytest\n",
    "from foo import Foo\n",
    "\n",
    "\n",
    "def test_string_check():\n",
    "    tester = Foo(8)\n",
    "    assert type(tester) is str\n",
    "\n",
    "\n",
    "def test_exception():\n",
    "    with pytest.raises(TypeError):\n",
    "        tester = Foo('8')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
